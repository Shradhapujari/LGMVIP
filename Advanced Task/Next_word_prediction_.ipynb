{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Next word prediction .ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgcWg2nrv8rp"
      },
      "source": [
        "# **Name - Shradha Pujari**\n",
        "# **Data Science Intern at LetsGrowMore**\n",
        "# **Advanced Level Task 2- Next Word Prediction** \n",
        "\n",
        "\n"
      ],
      "id": "PgcWg2nrv8rp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c31e2e15"
      },
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "id": "c31e2e15",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bd6d4f2"
      },
      "source": [
        "response=requests.get(\"http://www.gutenberg.org/cache/epub/5200/pg5200.txt\")"
      ],
      "id": "3bd6d4f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92c1ec73",
        "outputId": "717ddbdb-823d-4718-d487-cb585e6e9a83"
      },
      "source": [
        "response.text[:1500]\n"
      ],
      "id": "92c1ec73",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ufeffThe Project Gutenberg EBook of Metamorphosis, by Franz Kafka\\r\\nTranslated by David Wyllie.\\r\\n\\r\\nThis eBook is for the use of anyone anywhere at no cost and with\\r\\nalmost no restrictions whatsoever.  You may copy it, give it away or\\r\\nre-use it under the terms of the Project Gutenberg License included\\r\\nwith this eBook or online at www.gutenberg.org\\r\\n\\r\\n** This is a COPYRIGHTED Project Gutenberg eBook, Details Below **\\r\\n**     Please follow the copyright guidelines in this file.     **\\r\\n\\r\\n\\r\\nTitle: Metamorphosis\\r\\n\\r\\nAuthor: Franz Kafka\\r\\n\\r\\nTranslator: David Wyllie\\r\\n\\r\\nRelease Date: August 16, 2005 [EBook #5200]\\r\\nFirst posted: May 13, 2002\\r\\nLast updated: May 20, 2012\\r\\n\\r\\nLanguage: English\\r\\n\\r\\n\\r\\n*** START OF THIS PROJECT GUTENBERG EBOOK METAMORPHOSIS ***\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCopyright (C) 2002 David Wyllie.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  Metamorphosis\\r\\n  Franz Kafka\\r\\n\\r\\nTranslated by David Wyllie\\r\\n\\r\\n\\r\\n\\r\\nI\\r\\n\\r\\n\\r\\nOne morning, when Gregor Samsa woke from troubled dreams, he found\\r\\nhimself transformed in his bed into a horrible vermin.  He lay on\\r\\nhis armour-like back, and if he lifted his head a little he could\\r\\nsee his brown belly, slightly domed and divided by arches into stiff\\r\\nsections.  The bedding was hardly able to cover it and seemed ready\\r\\nto slide off any moment.  His many legs, pitifully thin compared\\r\\nwith the size of the rest of him, waved about helplessly as he\\r\\nlooked.\\r\\n\\r\\n\"What\\'s happened to me?\" he thought.  It wasn\\'t a dream.  His room,\\r\\na proper human room although a little too small, lay peacefully\\r\\nbetwee'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4994e5aa",
        "outputId": "0325b425-96cb-46ca-ddb9-8403e6e7fc9b"
      },
      "source": [
        "data = response.text.split('\\n')\n",
        "data[0]\n"
      ],
      "id": "4994e5aa",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ufeffThe Project Gutenberg EBook of Metamorphosis, by Franz Kafka\\r'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8a686a2",
        "outputId": "75df3d70-82bf-477a-8b10-0603044821d7"
      },
      "source": [
        "data = data[253:]\n",
        "data[0]\n"
      ],
      "id": "e8a686a2",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'away from the bed, bend down with the load and then be patient and\\r'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9519a478",
        "outputId": "bbc8fd7a-f56f-48c8-ed77-6880d1ecddbd"
      },
      "source": [
        "len(data)\n"
      ],
      "id": "9519a478",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2110"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d80366d5",
        "outputId": "6315ba13-0f21-4211-d803-be45a79cbc15"
      },
      "source": [
        "data = \" \".join(data)\n",
        "data[:1000]\n"
      ],
      "id": "d80366d5",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'away from the bed, bend down with the load and then be patient and\\r careful as he swang over onto the floor, where, hopefully, the\\r little legs would find a use.  Should he really call for help\\r though, even apart from the fact that all the doors were locked?\\r Despite all the difficulty he was in, he could not suppress a smile\\r at this thought.\\r \\r After a while he had already moved so far across that it would have\\r been hard for him to keep his balance if he rocked too hard.  The\\r time was now ten past seven and he would have to make a final\\r decision very soon.  Then there was a ring at the door of the flat.\\r \"That\\'ll be someone from work\", he said to himself, and froze very\\r still, although his little legs only became all the more lively as\\r they danced around.  For a moment everything remained quiet.\\r \"They\\'re not opening the door\", Gregor said to himself, caught in\\r some nonsensical hope.  But then of course, the maid\\'s firm steps\\r went to the door as ever and opened it.  Gregor on'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b57f5202",
        "outputId": "67e3c385-9b29-45c6-c841-1e03e821dbdb"
      },
      "source": [
        "def clean_text(doc):\n",
        " tokens = doc.split()\n",
        " table = str.maketrans('', '', string.punctuation)\n",
        " tokens = [w.translate(table) for w in tokens]\n",
        " tokens = [word for word in tokens if word.isalpha()]\n",
        " tokens = [word.lower() for word in tokens]\n",
        " return tokens\n",
        "tokens = clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "id": "b57f5202",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['away', 'from', 'the', 'bed', 'bend', 'down', 'with', 'the', 'load', 'and', 'then', 'be', 'patient', 'and', 'careful', 'as', 'he', 'swang', 'over', 'onto', 'the', 'floor', 'where', 'hopefully', 'the', 'little', 'legs', 'would', 'find', 'a', 'use', 'should', 'he', 'really', 'call', 'for', 'help', 'though', 'even', 'apart', 'from', 'the', 'fact', 'that', 'all', 'the', 'doors', 'were', 'locked', 'despite']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a9ca5eb",
        "outputId": "6c96c432-a688-4b69-9af1-334694f417bb"
      },
      "source": [
        "len(tokens)"
      ],
      "id": "2a9ca5eb",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22607"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c96355c2",
        "outputId": "a6104f19-23b4-46b6-8a4e-37927a5ba24c"
      },
      "source": [
        "length = 50 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq = tokens[i-length:i]\n",
        "  line = ' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i > 200000:\n",
        "   break\n",
        "\n",
        "print(len(lines))\n"
      ],
      "id": "c96355c2",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56f5de47"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "id": "56f5de47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d13135e"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "id": "0d13135e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f897512",
        "outputId": "2e004b27-5997-4c52-b060-bb7e5b121df0"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:,-1]\n",
        "X[0]\n"
      ],
      "id": "2f897512",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 103,   29,    1,  245, 2883,   98,   14,    1, 1435,    3,   48,\n",
              "         30,  618,    3,  756,   13,    6, 1434,  107,  165,    1,  149,\n",
              "         86, 2880,    1,   78,  225,   21,  530,   12,  156,  193,    6,\n",
              "        142,  754,   17,  180,  116,   49, 1433,   29,    1,  753,   11,\n",
              "         26,    1,  455,   58,  617,  329])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0d06fd3"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n"
      ],
      "id": "c0d06fd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d154834"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size)\n"
      ],
      "id": "5d154834",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e7ab6c9",
        "outputId": "5fd9eaf0-d54b-4b16-f004-5fc2e31236dc"
      },
      "source": [
        "seq_length = X.shape[1]\n",
        "seq_length"
      ],
      "id": "6e7ab6c9",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b833b713"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n"
      ],
      "id": "b833b713",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61cc8998",
        "outputId": "9fc87387-0273-4dbd-c45c-e3f5749653ec"
      },
      "source": [
        "model.summary()\n"
      ],
      "id": "61cc8998",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            144250    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2885)              291385    \n",
            "=================================================================\n",
            "Total params: 586,535\n",
            "Trainable params: 586,535\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe31513d"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
      ],
      "id": "fe31513d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2be800b",
        "outputId": "3af6fdbf-99ea-4487-be38-c2273084e298"
      },
      "source": [
        "model.fit(X, y, batch_size = 256, epochs = 100)"
      ],
      "id": "c2be800b",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "89/89 [==============================] - 36s 403ms/step - loss: 6.6534 - accuracy: 0.0464\n",
            "Epoch 2/100\n",
            "89/89 [==============================] - 33s 370ms/step - loss: 6.1880 - accuracy: 0.0540\n",
            "Epoch 3/100\n",
            "89/89 [==============================] - 32s 365ms/step - loss: 6.1551 - accuracy: 0.0540\n",
            "Epoch 4/100\n",
            "89/89 [==============================] - 33s 365ms/step - loss: 6.0518 - accuracy: 0.0540\n",
            "Epoch 5/100\n",
            "89/89 [==============================] - 33s 368ms/step - loss: 5.9690 - accuracy: 0.0541\n",
            "Epoch 6/100\n",
            "89/89 [==============================] - 33s 367ms/step - loss: 5.8392 - accuracy: 0.0593\n",
            "Epoch 7/100\n",
            "89/89 [==============================] - 32s 359ms/step - loss: 5.7397 - accuracy: 0.0664\n",
            "Epoch 8/100\n",
            "89/89 [==============================] - 33s 365ms/step - loss: 5.6532 - accuracy: 0.0732\n",
            "Epoch 9/100\n",
            "89/89 [==============================] - 34s 377ms/step - loss: 5.5703 - accuracy: 0.0771\n",
            "Epoch 10/100\n",
            "89/89 [==============================] - 35s 391ms/step - loss: 5.4973 - accuracy: 0.0825\n",
            "Epoch 11/100\n",
            "89/89 [==============================] - 32s 354ms/step - loss: 5.4175 - accuracy: 0.0884\n",
            "Epoch 12/100\n",
            "89/89 [==============================] - 31s 352ms/step - loss: 5.3321 - accuracy: 0.0932\n",
            "Epoch 13/100\n",
            "89/89 [==============================] - 32s 363ms/step - loss: 5.2377 - accuracy: 0.1031\n",
            "Epoch 14/100\n",
            "89/89 [==============================] - 30s 334ms/step - loss: 5.1354 - accuracy: 0.1085\n",
            "Epoch 15/100\n",
            "89/89 [==============================] - 35s 396ms/step - loss: 5.0173 - accuracy: 0.1135\n",
            "Epoch 16/100\n",
            "89/89 [==============================] - 20s 226ms/step - loss: 4.9329 - accuracy: 0.1174\n",
            "Epoch 17/100\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 4.8586 - accuracy: 0.1217\n",
            "Epoch 18/100\n",
            "89/89 [==============================] - 17s 191ms/step - loss: 4.7850 - accuracy: 0.1283\n",
            "Epoch 19/100\n",
            "89/89 [==============================] - 17s 189ms/step - loss: 4.7261 - accuracy: 0.1329\n",
            "Epoch 20/100\n",
            "89/89 [==============================] - 17s 190ms/step - loss: 4.6663 - accuracy: 0.1348\n",
            "Epoch 21/100\n",
            "89/89 [==============================] - 20s 222ms/step - loss: 4.6148 - accuracy: 0.1386\n",
            "Epoch 22/100\n",
            "89/89 [==============================] - 23s 257ms/step - loss: 4.5633 - accuracy: 0.1439\n",
            "Epoch 23/100\n",
            "89/89 [==============================] - 24s 269ms/step - loss: 4.5158 - accuracy: 0.1440\n",
            "Epoch 24/100\n",
            "89/89 [==============================] - 25s 284ms/step - loss: 4.4733 - accuracy: 0.1471\n",
            "Epoch 25/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 4.4291 - accuracy: 0.1498\n",
            "Epoch 26/100\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 4.3900 - accuracy: 0.1509\n",
            "Epoch 27/100\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 4.3473 - accuracy: 0.1543\n",
            "Epoch 28/100\n",
            "89/89 [==============================] - 18s 204ms/step - loss: 4.3087 - accuracy: 0.1562\n",
            "Epoch 29/100\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 4.2722 - accuracy: 0.1586\n",
            "Epoch 30/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 4.2290 - accuracy: 0.1612\n",
            "Epoch 31/100\n",
            "89/89 [==============================] - 18s 202ms/step - loss: 4.1910 - accuracy: 0.1649\n",
            "Epoch 32/100\n",
            "89/89 [==============================] - 17s 194ms/step - loss: 4.1578 - accuracy: 0.1657\n",
            "Epoch 33/100\n",
            "89/89 [==============================] - 19s 219ms/step - loss: 4.1212 - accuracy: 0.1683\n",
            "Epoch 34/100\n",
            "89/89 [==============================] - 19s 213ms/step - loss: 4.0861 - accuracy: 0.1716\n",
            "Epoch 35/100\n",
            "89/89 [==============================] - 19s 209ms/step - loss: 4.0489 - accuracy: 0.1755\n",
            "Epoch 36/100\n",
            "89/89 [==============================] - 20s 225ms/step - loss: 4.0141 - accuracy: 0.1778\n",
            "Epoch 37/100\n",
            "89/89 [==============================] - 19s 208ms/step - loss: 3.9785 - accuracy: 0.1799\n",
            "Epoch 38/100\n",
            "89/89 [==============================] - 17s 196ms/step - loss: 3.9523 - accuracy: 0.1819\n",
            "Epoch 39/100\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 3.9115 - accuracy: 0.1860\n",
            "Epoch 40/100\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 3.8771 - accuracy: 0.1895\n",
            "Epoch 41/100\n",
            "89/89 [==============================] - 18s 208ms/step - loss: 3.8506 - accuracy: 0.1915\n",
            "Epoch 42/100\n",
            "89/89 [==============================] - 22s 253ms/step - loss: 3.8134 - accuracy: 0.1946\n",
            "Epoch 43/100\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 3.8287 - accuracy: 0.1950\n",
            "Epoch 44/100\n",
            "89/89 [==============================] - 19s 210ms/step - loss: 3.8398 - accuracy: 0.1949\n",
            "Epoch 45/100\n",
            "89/89 [==============================] - 18s 206ms/step - loss: 3.7607 - accuracy: 0.2007\n",
            "Epoch 46/100\n",
            "89/89 [==============================] - 21s 238ms/step - loss: 3.7078 - accuracy: 0.2077\n",
            "Epoch 47/100\n",
            "89/89 [==============================] - 26s 288ms/step - loss: 3.6642 - accuracy: 0.2117\n",
            "Epoch 48/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 3.6294 - accuracy: 0.2151\n",
            "Epoch 49/100\n",
            "89/89 [==============================] - 19s 211ms/step - loss: 3.6000 - accuracy: 0.2182\n",
            "Epoch 50/100\n",
            "89/89 [==============================] - 18s 205ms/step - loss: 3.5772 - accuracy: 0.2213\n",
            "Epoch 51/100\n",
            "89/89 [==============================] - 24s 271ms/step - loss: 3.5445 - accuracy: 0.2248\n",
            "Epoch 52/100\n",
            "89/89 [==============================] - 20s 226ms/step - loss: 3.5105 - accuracy: 0.2303\n",
            "Epoch 53/100\n",
            "89/89 [==============================] - 17s 196ms/step - loss: 3.4758 - accuracy: 0.2355\n",
            "Epoch 54/100\n",
            "89/89 [==============================] - 19s 214ms/step - loss: 3.4474 - accuracy: 0.2397\n",
            "Epoch 55/100\n",
            "89/89 [==============================] - 18s 198ms/step - loss: 3.4203 - accuracy: 0.2406\n",
            "Epoch 56/100\n",
            "89/89 [==============================] - 19s 214ms/step - loss: 3.3891 - accuracy: 0.2469\n",
            "Epoch 57/100\n",
            "89/89 [==============================] - 18s 207ms/step - loss: 3.3894 - accuracy: 0.2483\n",
            "Epoch 58/100\n",
            "89/89 [==============================] - 18s 207ms/step - loss: 3.3703 - accuracy: 0.2497\n",
            "Epoch 59/100\n",
            "89/89 [==============================] - 18s 202ms/step - loss: 3.3278 - accuracy: 0.2546\n",
            "Epoch 60/100\n",
            "89/89 [==============================] - 18s 203ms/step - loss: 3.2881 - accuracy: 0.2622\n",
            "Epoch 61/100\n",
            "89/89 [==============================] - 18s 199ms/step - loss: 3.2594 - accuracy: 0.2657\n",
            "Epoch 62/100\n",
            "89/89 [==============================] - 18s 201ms/step - loss: 3.2934 - accuracy: 0.2627\n",
            "Epoch 63/100\n",
            "89/89 [==============================] - 17s 195ms/step - loss: 3.2281 - accuracy: 0.2725\n",
            "Epoch 64/100\n",
            "89/89 [==============================] - 17s 194ms/step - loss: 3.1821 - accuracy: 0.2787\n",
            "Epoch 65/100\n",
            "89/89 [==============================] - 17s 193ms/step - loss: 3.1514 - accuracy: 0.2828\n",
            "Epoch 66/100\n",
            "89/89 [==============================] - 18s 197ms/step - loss: 3.1249 - accuracy: 0.2900\n",
            "Epoch 67/100\n",
            "89/89 [==============================] - 21s 235ms/step - loss: 3.0996 - accuracy: 0.2897\n",
            "Epoch 68/100\n",
            "89/89 [==============================] - 23s 260ms/step - loss: 3.0731 - accuracy: 0.2966\n",
            "Epoch 69/100\n",
            "89/89 [==============================] - 20s 230ms/step - loss: 3.0453 - accuracy: 0.3000\n",
            "Epoch 70/100\n",
            "89/89 [==============================] - 19s 212ms/step - loss: 3.0191 - accuracy: 0.3035\n",
            "Epoch 71/100\n",
            "89/89 [==============================] - 21s 239ms/step - loss: 3.0113 - accuracy: 0.3059\n",
            "Epoch 72/100\n",
            "89/89 [==============================] - 19s 212ms/step - loss: 2.9867 - accuracy: 0.3119\n",
            "Epoch 73/100\n",
            "89/89 [==============================] - 19s 217ms/step - loss: 2.9721 - accuracy: 0.3150\n",
            "Epoch 74/100\n",
            "89/89 [==============================] - 19s 215ms/step - loss: 2.9364 - accuracy: 0.3151\n",
            "Epoch 75/100\n",
            "89/89 [==============================] - 19s 215ms/step - loss: 2.9092 - accuracy: 0.3223\n",
            "Epoch 76/100\n",
            "89/89 [==============================] - 19s 212ms/step - loss: 2.8794 - accuracy: 0.3279\n",
            "Epoch 77/100\n",
            "89/89 [==============================] - 22s 245ms/step - loss: 2.8554 - accuracy: 0.3324\n",
            "Epoch 78/100\n",
            "89/89 [==============================] - 19s 211ms/step - loss: 2.8243 - accuracy: 0.3403\n",
            "Epoch 79/100\n",
            "89/89 [==============================] - 18s 207ms/step - loss: 2.8022 - accuracy: 0.3425\n",
            "Epoch 80/100\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "89/89 [==============================] - 19s 213ms/step - loss: 2.7815 - accuracy: 0.3491\n",
            "Epoch 81/100\n",
            "89/89 [==============================] - 19s 212ms/step - loss: 2.7616 - accuracy: 0.3514\n",
            "Epoch 82/100\n",
            "89/89 [==============================] - 20s 227ms/step - loss: 2.7357 - accuracy: 0.3542\n",
            "Epoch 83/100\n",
            "89/89 [==============================] - 22s 246ms/step - loss: 2.7153 - accuracy: 0.3560\n",
            "Epoch 84/100\n",
            "89/89 [==============================] - 19s 214ms/step - loss: 2.6952 - accuracy: 0.3615\n",
            "Epoch 85/100\n",
            "89/89 [==============================] - 19s 219ms/step - loss: 2.6790 - accuracy: 0.3665\n",
            "Epoch 86/100\n",
            "89/89 [==============================] - 18s 207ms/step - loss: 2.6547 - accuracy: 0.3705\n",
            "Epoch 87/100\n",
            "89/89 [==============================] - 18s 205ms/step - loss: 2.6396 - accuracy: 0.3710\n",
            "Epoch 88/100\n",
            "89/89 [==============================] - 19s 212ms/step - loss: 2.6334 - accuracy: 0.3736\n",
            "Epoch 89/100\n",
            "89/89 [==============================] - 19s 212ms/step - loss: 2.6175 - accuracy: 0.3774\n",
            "Epoch 90/100\n",
            "89/89 [==============================] - 21s 230ms/step - loss: 2.5821 - accuracy: 0.3840\n",
            "Epoch 91/100\n",
            "89/89 [==============================] - 19s 209ms/step - loss: 2.5634 - accuracy: 0.3866\n",
            "Epoch 92/100\n",
            "89/89 [==============================] - 21s 236ms/step - loss: 2.5403 - accuracy: 0.3917\n",
            "Epoch 93/100\n",
            "89/89 [==============================] - 19s 216ms/step - loss: 2.5179 - accuracy: 0.3935\n",
            "Epoch 94/100\n",
            "89/89 [==============================] - 18s 207ms/step - loss: 2.4990 - accuracy: 0.4013\n",
            "Epoch 95/100\n",
            "89/89 [==============================] - 20s 223ms/step - loss: 2.4983 - accuracy: 0.3993\n",
            "Epoch 96/100\n",
            "89/89 [==============================] - 24s 273ms/step - loss: 2.4890 - accuracy: 0.3998\n",
            "Epoch 97/100\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 2.4698 - accuracy: 0.4014\n",
            "Epoch 98/100\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 2.4488 - accuracy: 0.4043\n",
            "Epoch 99/100\n",
            "89/89 [==============================] - 20s 220ms/step - loss: 2.4207 - accuracy: 0.4138\n",
            "Epoch 100/100\n",
            "89/89 [==============================] - 20s 225ms/step - loss: 2.4076 - accuracy: 0.4151\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x21c13c94e20>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6824b328",
        "outputId": "0dc9c7ba-dc31-41f0-d352-e991b9ae58ed"
      },
      "source": [
        "seed_text=lines[12343]\n",
        "seed_text"
      ],
      "id": "6824b328",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'condition seemed serious enough to remind even his father that gregor despite his current sad and revolting form was a family member who could not be treated as an enemy on the contrary as a family there was a duty to swallow any revulsion for him and to be patient just'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce04d8a2"
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "    text = []\n",
        "    \n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "        \n",
        "        y_predict = model.predict_classes(encoded)\n",
        "    \n",
        "        predicted_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == y_predict:\n",
        "                predicted_word = word\n",
        "                break \n",
        "        seed_text = seed_text + ' ' + predicted_word\n",
        "        text.append(predicted_word)\n",
        "    return ' '.join(text)\n"
      ],
      "id": "ce04d8a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8378757",
        "outputId": "4830f62e-52bc-486b-c2f1-fce7bba0d7c3"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)"
      ],
      "id": "b8378757",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'to be patient easy back closer that would threatened that he would have to be heard home the kitchen locked himself hidden as he was not a loss but the room he isnt we cant see it out of the door and listening him and the chief clerk but was still a minor discourtesy and the rooms gentleman in the endless holiday i appear immediate notice with the same conclusion for the time being blossoming as all playing he had poured their door on him and then they answered answered with confirmation of him and were very times to transport'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAisbkvjykzQ"
      },
      "source": [
        "# **Thank You!**"
      ],
      "id": "fAisbkvjykzQ"
    }
  ]
}